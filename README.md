# exploreAirflow

Airflow is a platform to programmatically author, schedule and monitor workflows or data pipelines.

A workflow is a sequence of task, started on a schedule or triggered by an event. Its frequently used to handle big data processing pipeline.

Below is an example of workflow:
  1.  Download data from source.
  2.  Send data somewhere else to process.
  3.  Monitor when the process is complete.
  4.  Get the result and generate the report.
  5.  Send a report out by mail.


